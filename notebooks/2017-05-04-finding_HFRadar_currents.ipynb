{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching data from a CSW catalog with Python tools\n",
    "\n",
    "This notebook shows a typical workflow to query a [Catalog Service for the Web (CSW)](https://en.wikipedia.org/wiki/Catalog_Service_for_the_Web) and create a request for data endpoints that are suitable for download.\n",
    "\n",
    "In this queries multiple catalogs for the near real time HF-Radar current data.\n",
    "\n",
    "The first step is to create the data filter based on the geographical region bounding box, the time span, and the CF variable standard name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[standard_names]:\n",
      "surface_northward_sea_water_velocity, surface_eastward_sea_water_velocity\n",
      "[start and stop dates]: 2017-08-17 10:27:23.373144 to 2017-08-24 10:27:23.373144\n",
      "[bounding box]:[-123, 36, -121, 40]:urn:ogc:def:crs:OGC:1.3:CRS84\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Region: West coast.\n",
    "min_lon, max_lon = -123, -121\n",
    "min_lat, max_lat = 36, 40\n",
    "\n",
    "bbox = [min_lon, min_lat, max_lon, max_lat]\n",
    "crs = 'urn:ogc:def:crs:OGC:1.3:CRS84'\n",
    "\n",
    "# Temporal range: past week.\n",
    "now = datetime.utcnow()\n",
    "start, stop = now - timedelta(days=(14)), now - timedelta(days=(7))\n",
    "\n",
    "# Surface velocity CF names.\n",
    "cf_names = ['surface_northward_sea_water_velocity',\n",
    "            'surface_eastward_sea_water_velocity']\n",
    "\n",
    "msg = '[standard_names]:\\n{cf_names}\\n[start and stop dates]: {start} to {stop}\\n[bounding box]:{bbox}:{crs}'.format\n",
    "print(msg(**{\n",
    "    'cf_names': ', '.join(cf_names),\n",
    "    'start': start,\n",
    "    'stop': stop,\n",
    "    'bbox': bbox,\n",
    "    'crs': crs,\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is possible to assemble a [OGC Filter Encoding (FE)](http://www.opengeospatial.org/standards/filter) for the search using `owslib.fes`\\*. Note that the final result is only a list with all the filtering conditions.\n",
    "\n",
    "\\* OWSLib is a Python package for client programming with Open Geospatial Consortium (OGC) web service (hence OWS) interface standards, and their related content models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from owslib import fes\n",
    "\n",
    "\n",
    "def fes_date_filter(start, stop, constraint='overlaps'):\n",
    "    \"\"\"\n",
    "    Take datetime-like objects and returns a fes filter for date range\n",
    "    (begin and end inclusive).\n",
    "    NOTE: Truncates the minutes!!!\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from datetime import datetime, timedelta\n",
    "    >>> stop = datetime(2010, 1, 1, 12, 30, 59).replace(tzinfo=pytz.utc)\n",
    "    >>> start = stop - timedelta(days=7)\n",
    "    >>> begin, end = fes_date_filter(start, stop, constraint='overlaps')\n",
    "    >>> begin.literal, end.literal\n",
    "    ('2010-01-01 12:00', '2009-12-25 12:00')\n",
    "    >>> begin.propertyoperator, end.propertyoperator\n",
    "    ('ogc:PropertyIsLessThanOrEqualTo', 'ogc:PropertyIsGreaterThanOrEqualTo')\n",
    "    >>> begin, end = fes_date_filter(start, stop, constraint='within')\n",
    "    >>> begin.literal, end.literal\n",
    "    ('2009-12-25 12:00', '2010-01-01 12:00')\n",
    "    >>> begin.propertyoperator, end.propertyoperator\n",
    "    ('ogc:PropertyIsGreaterThanOrEqualTo', 'ogc:PropertyIsLessThanOrEqualTo')\n",
    "\n",
    "    \"\"\"\n",
    "    start = start.strftime('%Y-%m-%d %H:00')\n",
    "    stop = stop.strftime('%Y-%m-%d %H:00')\n",
    "    if constraint == 'overlaps':\n",
    "        propertyname = 'apiso:TempExtent_begin'\n",
    "        begin = fes.PropertyIsLessThanOrEqualTo(propertyname=propertyname,\n",
    "                                                literal=stop)\n",
    "        propertyname = 'apiso:TempExtent_end'\n",
    "        end = fes.PropertyIsGreaterThanOrEqualTo(propertyname=propertyname,\n",
    "                                                 literal=start)\n",
    "    elif constraint == 'within':\n",
    "        propertyname = 'apiso:TempExtent_begin'\n",
    "        begin = fes.PropertyIsGreaterThanOrEqualTo(propertyname=propertyname,\n",
    "                                                   literal=start)\n",
    "        propertyname = 'apiso:TempExtent_end'\n",
    "        end = fes.PropertyIsLessThanOrEqualTo(propertyname=propertyname,\n",
    "                                              literal=stop)\n",
    "    else:\n",
    "        raise NameError('Unrecognized constraint {}'.format(constraint))\n",
    "    return begin, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kw = dict(wildCard='*', escapeChar='\\\\',\n",
    "          singleChar='?', propertyname='apiso:AnyText')\n",
    "\n",
    "or_filt = fes.Or([fes.PropertyIsLike(literal=('*%s*' % val), **kw)\n",
    "                  for val in cf_names])\n",
    "\n",
    "# Exclude GNOME returns.\n",
    "not_filt = fes.Not([fes.PropertyIsLike(literal='*GNOME*', **kw)])\n",
    "\n",
    "begin, end = fes_date_filter(start, stop)\n",
    "bbox_crs = fes.BBox(bbox, crs=crs)\n",
    "filter_list = [fes.And([bbox_crs, begin, end, or_filt, not_filt])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to use the same filter to search multiple catalogs. The cell below loops over 3 catalogs hoping to find which one is more up-to-date and returns the near real time data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_csw_records(csw, filter_list, pagesize=10, maxrecords=1000):\n",
    "    \"\"\"Iterate `maxrecords`/`pagesize` times until the requested value in\n",
    "    `maxrecords` is reached.\n",
    "    \"\"\"\n",
    "    from owslib.fes import SortBy, SortProperty\n",
    "    # Iterate over sorted results.\n",
    "    sortby = SortBy([SortProperty('dc:title', 'ASC')])\n",
    "    csw_records = {}\n",
    "    startposition = 0\n",
    "    nextrecord = getattr(csw, 'results', 1)\n",
    "    while nextrecord != 0:\n",
    "        csw.getrecords2(constraints=filter_list, startposition=startposition,\n",
    "                        maxrecords=pagesize, sortby=sortby)\n",
    "        csw_records.update(csw.records)\n",
    "        if csw.results['nextrecord'] == 0:\n",
    "            break\n",
    "        startposition += pagesize + 1  # Last one is included.\n",
    "        if startposition >= maxrecords:\n",
    "            break\n",
    "    csw.records.update(csw_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 records.\n",
      "\n",
      "[CeNCOOS/Models/ROMS/California ROMS/California Coastal Regional Ocean Modeling System (ROMS) Nowcast]: CA_DAS\n",
      "[HYbrid Coordinate Ocean Model (HYCOM): Global]: hycom_global\n",
      "[UCSC California Current System ROMS Nowcast 10km]: UCSC\n"
     ]
    }
   ],
   "source": [
    "from owslib.csw import CatalogueServiceWeb\n",
    "\n",
    "\n",
    "endpoint = 'https://data.ioos.us/csw'\n",
    "\n",
    "csw = CatalogueServiceWeb(endpoint, timeout=60)\n",
    "get_csw_records(csw, filter_list, pagesize=10, maxrecords=1000)\n",
    "\n",
    "records = '\\n'.join(csw.records.keys())\n",
    "print('Found {} records.\\n'.format(len(csw.records.keys())))\n",
    "for key, value in list(csw.records.items()):\n",
    "    print('[{}]: {}'.format(value.title, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!FIXME!!!\n",
    "\n",
    "None of those looks like NDBC endpotins!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found some weird named data (looks like `uuid`) and some model/reanalysis data, .\n",
    "The weird data may be what we are looking for.\n",
    "Let's dig further using the 6 km resolution data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'c1fc179d-d567-4934-9720-29ae2b0f687c'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d0a4c0ec76de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'c1fc179d-d567-4934-9720-29ae2b0f687c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstract\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'c1fc179d-d567-4934-9720-29ae2b0f687c'"
     ]
    }
   ],
   "source": [
    "value = csw.records['c1fc179d-d567-4934-9720-29ae2b0f687c']\n",
    "\n",
    "print(value.abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the record abstract it seems that  this is exactly what we want.\n",
    "\n",
    "The next step is to inspect the type services/schemes available for downloading the data. The easiest way to accomplish that is with by \"sniffing\" the URLs with `geolinks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from geolinks import sniff_link\n",
    "\n",
    "msg = 'geolink: {geolink}\\nscheme: {scheme}\\nURL: {url}\\n'.format\n",
    "for ref in value.references:\n",
    "    print(msg(geolink=sniff_link(ref['url']), **ref))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!FIXME!!!\n",
    "\n",
    "We could not find anything with geolink. Let's try to investigate what we have in that record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all attributes\n",
    "attrs = [attr for attr in dir(value) if not attr.startswith('_')]\n",
    "attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# those that are not empty\n",
    "nonzero = [attr for attr in attrs if getattr(value, attr)]\n",
    "nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's print them out to see if we can find an endpoint to the data.\n",
    "\n",
    "for attr in nonzero:\n",
    "    print('[{}]: {}\\n'.format(attr, getattr(value, attr)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a detailed description of what those `geolink` results mean check the [lookup](https://github.com/OSGeo/Cat-Interop/blob/master/LinkPropertyLookupTable.csv) table.\n",
    "There are Web Coverage Service (WCS), Web Map Service (WMS),\n",
    "direct links, and OPeNDAP (identified as `None` !?) services available.\n",
    "\n",
    "The easiest one to explore is the open OPeNDAP endpoint.\n",
    "The next 5 cells downloads and plot the current data for the day before,\n",
    "to check if the endpoint is indeed near real time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!FIXME!!!\n",
    "\n",
    "Hardcoding the NDBC OPenDAP endpoint for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "url = 'http://sdf.ndbc.noaa.gov/thredds/dodsC/hfradar_uswc_6km'\n",
    "\n",
    "ds = xr.open_dataset(url)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select \"yesterday\" data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!FIXME!!!\n",
    "\n",
    "For some reason the dates are not CF-compliant and need to be parsed before we can work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds['time'] = [datetime.strptime(date.decode(), '%Y-%m-%dT%H:%M:%SZ') for date in ds['time'].data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "yesterday = date.today() - timedelta(days=1)\n",
    "\n",
    "ds = ds.sel(time=yesterday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the speed while masking invalid values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy.ma as ma\n",
    "\n",
    "u = ds['u'].data\n",
    "v = ds['v'].data\n",
    "\n",
    "lon = ds.coords['lon'].data\n",
    "lat = ds.coords['lat'].data\n",
    "time = ds.coords['time'].data\n",
    "\n",
    "u = ma.masked_invalid(u)\n",
    "v = ma.masked_invalid(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is only a trick to show all quiver arrows with the same length,\n",
    "for visualization purposes,\n",
    "and indicate the vector magnitude with colors instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from oceans import uv2spdir, spdir2uv\n",
    "\n",
    "angle, speed = uv2spdir(u, v)\n",
    "us, vs = spdir2uv(np.ones_like(speed), angle, deg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cartopy import feature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "LAND = feature.NaturalEarthFeature('physical', 'land', '10m',\n",
    "                                   edgecolor='face',\n",
    "                                   facecolor='lightgray')\n",
    "\n",
    "sub = 2\n",
    "dx = dy = 0.5\n",
    "center = -122.416667, 37.783333  # San Francisco.\n",
    "bbox = lon.min(), lon.max(), lat.min(), lat.max()\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(\n",
    "    ncols=2,\n",
    "    figsize=(15, 7),\n",
    "    subplot_kw=dict(projection=ccrs.PlateCarree())\n",
    ")\n",
    "\n",
    "\n",
    "ax0.set_extent(bbox)\n",
    "ax0.pcolormesh(lon, lat, ma.masked_invalid(speed))\n",
    "gl = ax0.gridlines(draw_labels=True)\n",
    "gl.xlabels_top = gl.ylabels_right = False\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "\n",
    "ax0.add_feature(LAND, zorder=0, edgecolor='black')\n",
    "\n",
    "\n",
    "ax1.set_extent([center[0]-dx-dx, center[0]+dx, center[1]-dy, center[1]+dy])\n",
    "ax1.quiver(lon[::sub], lat[::sub],\n",
    "           us[::sub, ::sub], vs[::sub, ::sub],\n",
    "           speed[::sub, ::sub], scale=30)\n",
    "gl = ax1.gridlines(draw_labels=True)\n",
    "gl.xlabels_top = gl.ylabels_right = False\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "\n",
    "ax1.add_feature(LAND, zorder=0, edgecolor='black')\n",
    "ax1.plot(ds['site_lon'], ds['site_lat'], marker='o', linestyle='none', color='darkorange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is yesterday's sea surface currents from the west coast with a zoom in the bay area.\n",
    "\n",
    "\n",
    "<br>\n",
    "Right click and choose Save link as... to\n",
    "[download](https://raw.githubusercontent.com/ioos/notebooks_demos/master/notebooks/2016-11-20-finding_HFRadar_currents.ipynb)\n",
    "this notebook, or see a static view\n",
    "[here](http://nbviewer.ipython.org/urls/raw.githubusercontent.com/ioos/notebooks_demos/master/notebooks/2016-11-20-finding_HFRadar_currents.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!FIXME!!!\n",
    "\n",
    "Retry the search without the date filter to check if we can find the NDBC data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_list = [\n",
    "    fes.And(\n",
    "        [\n",
    "            bbox_crs,\n",
    "            or_filt,\n",
    "            not_filt,\n",
    "            fes.Not([fes.PropertyIsLike(literal='*FVCOM*', **kw)]),\n",
    "            fes.Not([fes.PropertyIsLike(literal='*ROMS*', **kw)]),\n",
    "            fes.Not([fes.PropertyIsLike(literal='*SELFE*', **kw)]),\n",
    "            fes.Not([fes.PropertyIsLike(literal='*ncep_global*', **kw)]),\n",
    "            fes.Not([fes.PropertyIsLike(literal='*hycom_global*', **kw)]),\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "csw = CatalogueServiceWeb(endpoint, timeout=60)\n",
    "get_csw_records(csw, filter_list, pagesize=10, maxrecords=1000)\n",
    "\n",
    "records = '\\n'.join(csw.records.keys())\n",
    "print('Found {} records.\\n'.format(len(csw.records.keys())))\n",
    "for key, value in list(csw.records.items()):\n",
    "    print('[{}]: {}'.format(value.title, key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "value = csw.records['hfradar_uswc_6km']\n",
    "\n",
    "print(value.abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from geolinks import sniff_link\n",
    "\n",
    "msg = 'geolink: {geolink}\\nscheme: {scheme}\\nURL: {url}\\n'.format\n",
    "for ref in value.references:\n",
    "    print(msg(geolink=sniff_link(ref['url']), **ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "value.references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!FIXME!!!\n",
    "\n",
    "It is worth noting that the OPeNDAP endpoint has both geolink and scheme as `None` making it impossible to identify automagically."
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/e2ebe5b43f81f728d8f4b5089c8e798a"
  },
  "gist": {
   "data": {
    "description": "2017-05-04-finding_HFRadar_currents.ipynb",
    "public": true
   },
   "id": "e2ebe5b43f81f728d8f4b5089c8e798a"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
